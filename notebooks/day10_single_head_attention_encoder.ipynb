{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8047801",
   "metadata": {},
   "source": [
    "# Single-Head Self-Attention Encoder (Pre-LN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e376fa5",
   "metadata": {},
   "source": [
    "- Build a single-head self-attention *encoder block* (Pre-LN) <br>\n",
    "- Add sinusoidal positional encoding (absolute) <br>\n",
    "- Add a position-wise FFN <br>\n",
    "- Pool (CLS or masked-mean) -> linear head for tiny classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b9eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42029f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "D_MODEL = 32\n",
    "P_DROP = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2037c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab helpers\n",
    "def build_vocab(sentences: List[str], min_freq: int = 1) -> Dict[str, int]:\n",
    "    freq = {}\n",
    "    for s in sentences:\n",
    "        for w in s.split():\n",
    "            freq[w] = freq.get(w, 0) + 1\n",
    "    words = [w for w, c in sorted(freq.items(), key=lambda x: (-x[1], x[0])) if c >= min_freq]\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1}\n",
    "    for w in words:\n",
    "        vocab[w] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "def tokenize(s: str) -> List[str]: return s.strip().split()\n",
    "def numericalize(tokens: List[str], vocab: Dict[str,int]) -> List[int]:\n",
    "    return [vocab.get(t, vocab[UNK_TOKEN]) for t in tokens]\n",
    "\n",
    "def pad_batch(batch_ids: List[List[int]], pad_id: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    T = max(len(x) for x in batch_ids)\n",
    "    padded, mask = [], []\n",
    "    for ids in batch_ids:\n",
    "        pad_len = T - len(ids)\n",
    "        padded.append(ids + [pad_id]*pad_len)\n",
    "        mask.append([1]*len(ids) + [0]*pad_len)\n",
    "    return torch.tensor(padded, dtype=torch.long), torch.tensor(mask, dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862c2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding (sinusoidal)\n",
    "class SinusoidalPE(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)               # [Tmax, D]\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # [Tmax, 1]\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # [D/2]\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe)                   # not trainable\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x: [B,T,D]\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:T].unsqueeze(0)              # broadcast add, a simple elementwise add encodes positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f387d0",
   "metadata": {},
   "source": [
    "Q = what I seek, K = how findable I am, V = what I give. <br>\n",
    "\n",
    "Attention scores use Q·K; the update is a softmax-weighted mix of V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600cff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-head self-attention\n",
    "class SelfAttention1H(nn.Module): # attention (context mixing)\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.scale = math.sqrt(d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x:    [B,T,D], mask: [B,T] (True=real token)\n",
    "        returns:\n",
    "          out:  [B,T,D]\n",
    "          attn: [B,T,T] attention matrix (row: query token, col: key token)\n",
    "        \"\"\"\n",
    "        Q, K, V = self.q(x), self.k(x), self.v(x)             # [B,T,D]\n",
    "        scores = torch.matmul(Q, K.transpose(1, 2)) / self.scale  # [B,T,T]\n",
    "        key_mask = mask.unsqueeze(1)                           # [B,1,T]\n",
    "        scores = scores.masked_fill(~key_mask, float(\"-inf\"))  # forbid attending to PADs\n",
    "        attn = torch.softmax(scores, dim=-1)                   # [B,T,T]\n",
    "        out = torch.matmul(attn, V)                            # [B,T,D]\n",
    "        return out, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f547569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise FFN: get nonlinear feature interactions after attention has aggregated context\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int = 128, p_drop: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff), # Typical setting is d_ff ≈ 4 * d_model in Transformers\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(p_drop),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7caf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-LN Encoder Block (single head)\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, p_drop: float = 0.1, ffn_mult: int = 4):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.attn = SelfAttention1H(d_model)\n",
    "        self.drop1 = nn.Dropout(p_drop)\n",
    "\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FFN(d_model, d_ff=ffn_mult*d_model, p_drop=0.0)\n",
    "        self.drop2 = nn.Dropout(p_drop)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 1) pre-LN + residual around attention\n",
    "        y, attn = self.attn(self.ln1(x), mask)\n",
    "        x = x + self.drop1(y)\n",
    "        # 2) pre-LN + residual around FFN\n",
    "        y = self.ffn(self.ln2(x))\n",
    "        x = x + self.drop2(y)\n",
    "        return x, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341a0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder + pooling + head\n",
    "@dataclass\n",
    "class ModelCfg:\n",
    "    vocab_size: int\n",
    "    d_model: int\n",
    "    pad_id: int\n",
    "    pool: str = \"cls\"   # \"cls\" or \"mean\"\n",
    "\n",
    "class SingleHeadEncoderClassifier(nn.Module):\n",
    "    def __init__(self, cfg: ModelCfg):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(cfg.vocab_size, cfg.d_model, padding_idx=cfg.pad_id)\n",
    "        self.pe = SinusoidalPE(cfg.d_model)\n",
    "        self.block = EncoderBlock(cfg.d_model, p_drop=P_DROP)\n",
    "        self.final_ln = nn.LayerNorm(cfg.d_model)  # final LN is common in Pre-LN stacks\n",
    "        self.head = nn.Linear(cfg.d_model, 1)\n",
    "        self.pool = cfg.pool\n",
    "        self.pad_id = cfg.pad_id\n",
    "\n",
    "    def masked_mean(self, x, mask):               # x:[B,T,D], mask:[B,T]\n",
    "        m = mask.float().unsqueeze(-1)\n",
    "        return (x*m).sum(1) / m.sum(1).clamp(min=1.0)\n",
    "\n",
    "    def forward(self, ids: torch.Tensor, mask: torch.Tensor):\n",
    "        x = self.embed(ids)                       # [B,T,D]\n",
    "        x = self.pe(x)                            # add sinusoidal positions\n",
    "        x, attn = self.block(x, mask)             # [B,T,D], [B,T,T]\n",
    "        x = self.final_ln(x)\n",
    "\n",
    "        if self.pool == \"mean\":\n",
    "            sent = self.masked_mean(x, mask)      # [B,D]\n",
    "        else:\n",
    "            sent = x[:, 0, :]                     # first-token (CLS-style): take the hidden state of that token as the whole-sentence representation\n",
    "\n",
    "        logits = self.head(sent).squeeze(-1)      # [B]\n",
    "        return logits, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ed8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_hard = [\n",
    "    \"good morning everyone\",\n",
    "    \"hello there my friend\",\n",
    "    \"hey buddy how are you\",\n",
    "    \"good evening folks\",\n",
    "    \"salutations from the sushi bar\",          # greeting + food word\n",
    "    \"pizza party greetings to all\",            # greeting + food word\n",
    "    \"hi from the ramen shop\",                  # greeting + food word\n",
    "    \"hello and welcome to brunch\",             # greeting + food word\n",
    "]\n",
    "food_hard = [\n",
    "    \"i love pizza\",\n",
    "    \"pasta is tasty tonight\",\n",
    "    \"fresh salad with apple\",\n",
    "    \"i like sushi a lot\",\n",
    "    \"good sandwich this morning\",              # food + greeting words\n",
    "    \"ramen is great hello world\",              # food + greeting word\n",
    "    \"eating an apple for breakfast\",\n",
    "    \"not a fan of pizza anymore\",              # negation\n",
    "]\n",
    "HARD_SUP = greeting_hard + food_hard\n",
    "HARD_LABELS = [0]*len(greeting_hard) + [1]*len(food_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f07f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add a real <cls> token and batching with CLS ---\n",
    "CLS_TOKEN = \"<cls>\"\n",
    "\n",
    "def build_vocab_with_specials(sentences):\n",
    "    base = build_vocab(sentences)\n",
    "    # reserve 0/1/2 = <pad>/<unk>/<cls>\n",
    "    vocab = {PAD_TOKEN: 0, UNK_TOKEN: 1, CLS_TOKEN: 2}\n",
    "    next_id = 3\n",
    "    for w in base:\n",
    "        if w in (PAD_TOKEN, UNK_TOKEN):  # skip if already special\n",
    "            continue\n",
    "        vocab[w] = next_id\n",
    "        next_id += 1\n",
    "    return vocab\n",
    "\n",
    "# Build vocab with <cls>\n",
    "VOCAB = build_vocab_with_specials(HARD_SUP)\n",
    "pad_id, cls_id = VOCAB[PAD_TOKEN], VOCAB[CLS_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc5c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch_with_cls(batch_ids, pad_id, cls_id):\n",
    "    with_cls = [[cls_id] + ids for ids in batch_ids]\n",
    "    T = max(len(x) for x in with_cls)\n",
    "    padded, mask = [], []\n",
    "    for ids in with_cls:\n",
    "        pad_len = T - len(ids)\n",
    "        padded.append(ids + [pad_id]*pad_len)\n",
    "        mask.append([1]*len(ids) + [0]*pad_len)\n",
    "    X = torch.tensor(padded, dtype=torch.long)\n",
    "    M = torch.tensor(mask, dtype=torch.bool)\n",
    "    return X, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a21501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple split (80/20) ---\n",
    "def split_train_val(sentences, labels, val_frac=0.2, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "    idx = list(range(len(sentences)))\n",
    "    rng.shuffle(idx)\n",
    "    cut = max(1, int(len(idx) * (1 - val_frac)))\n",
    "    tr_idx, va_idx = idx[:cut], idx[cut:]\n",
    "    tr_s = [sentences[i] for i in tr_idx]\n",
    "    tr_y = [labels[i] for i in tr_idx]\n",
    "    va_s = [sentences[i] for i in va_idx]\n",
    "    va_y = [labels[i] for i in va_idx]\n",
    "    return tr_s, tr_y, va_s, va_y\n",
    "\n",
    "tr_s, tr_y, va_s, va_y = split_train_val(HARD_SUP, HARD_LABELS, val_frac=0.25, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ac1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset → tensors \n",
    "def make_tensors(sentences, labels, vocab, pad_id, cls_id):\n",
    "    tok = [tokenize(s) for s in sentences]\n",
    "    ids = [numericalize(t, vocab) for t in tok]\n",
    "    X, M = pad_batch_with_cls(ids, pad_id, cls_id)\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    return X, M, y\n",
    "\n",
    "Xtr, Mtr, ytr = make_tensors(tr_s, tr_y, VOCAB, pad_id, cls_id)\n",
    "Xva, Mva, yva = make_tensors(va_s, va_y, VOCAB, pad_id, cls_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_step(model, X, M, y, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(X, M)\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, y)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold).float()\n",
    "        acc = (preds == y).float().mean().item()\n",
    "        brier = (probs - y).pow(2).mean().item()\n",
    "        margin = (probs - 0.5).abs().mean().item()\n",
    "    return loss.item(), acc, brier, margin\n",
    "\n",
    "# --- Train loop (mini-batch) ---\n",
    "def train_encoder(model, Xtr, Mtr, ytr, Xva, Mva, yva,\n",
    "                  epochs=80, batch_size=8, lr=3e-3, weight_decay=1e-4,\n",
    "                  patience=8, min_delta=1e-4, clip=1.0, verbose=True):\n",
    "    device = next(model.parameters()).device\n",
    "    Xtr, Mtr, ytr = Xtr.to(device), Mtr.to(device), ytr.to(device)\n",
    "    Xva, Mva, yva = Xva.to(device), Mva.to(device), yva.to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "\n",
    "    N = Xtr.size(0)\n",
    "    for e in range(1, epochs+1):\n",
    "        model.train()\n",
    "        # simple mini-batch loop\n",
    "        perm = torch.randperm(N, device=device) # returns a random permutation of integers from 0 to n - 1\n",
    "        total_loss = 0.0\n",
    "        for i in range(0, N, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            xb, mb, yb = Xtr[idx], Mtr[idx], ytr[idx]\n",
    "            opt.zero_grad()\n",
    "            logits, _ = model(xb, mb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            if clip: # scales all grads down uniformly so the norm equals max_norm.\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss = total_loss / N\n",
    "        val_loss, val_acc, val_brier, val_margin = evaluate_step(model, Xva, Mva, yva)\n",
    "\n",
    "        if verbose and (e % 5 == 0 or e == 1):\n",
    "            print(f\"epoch {e:03d} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} | val_acc={val_acc:.3f} | \"\n",
    "                  f\"val_brier={val_brier:.4f} | val_margin={val_margin:.3f}\")\n",
    "\n",
    "        # early stopping on val loss\n",
    "        if best_val - val_loss > min_delta:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"early stop at epoch {e} | best_val_loss={best_val:.4f}\")\n",
    "                break\n",
    "        \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "417b5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 | train_loss=0.6810 | val_loss=0.8285 | val_acc=0.250 | val_brier=0.3164 | val_margin=0.119\n",
      "epoch 005 | train_loss=0.5749 | val_loss=0.8381 | val_acc=0.250 | val_brier=0.3211 | val_margin=0.149\n",
      "epoch 010 | train_loss=0.2093 | val_loss=1.1494 | val_acc=0.500 | val_brier=0.4224 | val_margin=0.286\n",
      "early stop at epoch 11 | best_val_loss=0.7269\n",
      "TRAIN  loss=0.6137 acc=0.833 brier=0.2108 margin=0.054\n",
      "VALID  loss=0.7269 acc=0.250 brier=0.2669 margin=0.060\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "cfg = ModelCfg(vocab_size=len(VOCAB), d_model=D_MODEL, pad_id=pad_id, pool=\"cls\")  # try \"mean\" too\n",
    "model = SingleHeadEncoderClassifier(cfg).to(DEVICE)\n",
    "\n",
    "# Train\n",
    "model = train_encoder(model, Xtr, Mtr, ytr, Xva, Mva, yva,\n",
    "                        epochs=80, batch_size=8, lr=3e-3, weight_decay=1e-4,\n",
    "                        patience=8, min_delta=1e-4, clip=1.0, verbose=True)\n",
    "\n",
    "# Final report on train + val\n",
    "tr_metrics = evaluate_step(model, Xtr.to(DEVICE), Mtr.to(DEVICE), ytr.to(DEVICE))\n",
    "va_metrics = evaluate_step(model, Xva.to(DEVICE), Mva.to(DEVICE), yva.to(DEVICE))\n",
    "print(f\"TRAIN  loss={tr_metrics[0]:.4f} acc={tr_metrics[1]:.3f} brier={tr_metrics[2]:.4f} margin={tr_metrics[3]:.3f}\")\n",
    "print(f\"VALID  loss={va_metrics[0]:.4f} acc={va_metrics[1]:.3f} brier={va_metrics[2]:.4f} margin={va_metrics[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12ec9f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 001 | train_loss=0.7326 | val_loss=0.7517 | val_acc=0.000 | val_brier=0.2792 | val_margin=0.028\n",
      "epoch 005 | train_loss=0.4753 | val_loss=0.9579 | val_acc=0.250 | val_brier=0.3739 | val_margin=0.125\n",
      "early stop at epoch 9 | best_val_loss=0.7517\n",
      "TRAIN  loss=0.6538 acc=0.833 brier=0.2304 margin=0.065\n",
      "VALID  loss=0.7517 acc=0.000 brier=0.2792 margin=0.028\n"
     ]
    }
   ],
   "source": [
    "# Try pool=\"mean\" vs pool=\"cls\" and see which is better without pretraining.\n",
    "cfg2 = ModelCfg(vocab_size=len(VOCAB), d_model=D_MODEL, pad_id=pad_id, pool=\"mean\")  # try \"mean\" too\n",
    "model2 = SingleHeadEncoderClassifier(cfg2).to(DEVICE)\n",
    "\n",
    "# Train\n",
    "model2 = train_encoder(model2, Xtr, Mtr, ytr, Xva, Mva, yva,\n",
    "                        epochs=80, batch_size=8, lr=3e-3, weight_decay=1e-4,\n",
    "                        patience=8, min_delta=1e-4, clip=1.0, verbose=True)\n",
    "\n",
    "# Final report on train + val\n",
    "tr_metrics = evaluate_step(model2, Xtr.to(DEVICE), Mtr.to(DEVICE), ytr.to(DEVICE))\n",
    "va_metrics = evaluate_step(model2, Xva.to(DEVICE), Mva.to(DEVICE), yva.to(DEVICE))\n",
    "print(f\"TRAIN  loss={tr_metrics[0]:.4f} acc={tr_metrics[1]:.3f} brier={tr_metrics[2]:.4f} margin={tr_metrics[3]:.3f}\")\n",
    "print(f\"VALID  loss={va_metrics[0]:.4f} acc={va_metrics[1]:.3f} brier={va_metrics[2]:.4f} margin={va_metrics[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c882331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head-only warm start (few epochs) → then unfreeze encoder\n",
    "def freeze(module, flag: bool):\n",
    "    for p in module.parameters(): p.requires_grad = flag\n",
    "\n",
    "def train_encoder_warm_start(model, Xtr, Mtr, ytr, Xva, Mva, yva,\n",
    "                  epochs=60, warm_epochs=5, batch_size=8, weight_decay=1e-4,\n",
    "                  patience_warm=2, patience_full=4, min_delta=1e-4, clip=1.0, verbose=True):\n",
    "    device = next(model.parameters()).device\n",
    "    Xtr, Mtr, ytr = Xtr.to(device), Mtr.to(device), ytr.to(device)\n",
    "    Xva, Mva, yva = Xva.to(device), Mva.to(device), yva.to(device)\n",
    "\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "    # Warm start head-only (encoder frozen)\n",
    "    freeze(model.embed, False)\n",
    "    freeze(model.block, False)\n",
    "    opt = torch.optim.Adam(list(model.final_ln.parameters()) + list(model.head.parameters()), lr=1e-3, weight_decay=0)\n",
    "    # (optionally) also freeze model.head.scale during warm start if using cosine head\n",
    "\n",
    "    N = Xtr.size(0)\n",
    "    for e in range(1, warm_epochs+1):\n",
    "        model.train()\n",
    "        # simple mini-batch loop\n",
    "        perm = torch.randperm(N, device=device) # returns a random permutation of integers from 0 to n - 1\n",
    "        total_loss = 0.0\n",
    "        for i in range(0, N, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            xb, mb, yb = Xtr[idx], Mtr[idx], ytr[idx]\n",
    "            opt.zero_grad()\n",
    "            logits, _ = model(xb, mb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            if clip: # scales all grads down uniformly so the norm equals max_norm.\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss = total_loss / N\n",
    "        val_loss, val_acc, val_brier, val_margin = evaluate_step(model, Xva, Mva, yva)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Warm start epoch {e:03d} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} | val_acc={val_acc:.3f} | \"\n",
    "                  f\"val_brier={val_brier:.4f} | val_margin={val_margin:.3f}\")\n",
    "        # early stopping on val loss\n",
    "        if best_val - val_loss > min_delta:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience_warm:\n",
    "                if verbose:\n",
    "                    print(f\"early stop at epoch {e} | best_val_loss={best_val:.4f}\")\n",
    "                break\n",
    "\n",
    "\n",
    "    # Restore best-so-far before unfreezing to start Stage-2 from best point\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    # After warm start → unfreeze encoder if training from scratch\n",
    "    freeze(model.embed, True)\n",
    "    freeze(model.block, True)\n",
    "    # rebuild optimizer with different LRs for emb vs head\n",
    "    enc_params  = [p for n,p in model.named_parameters()\n",
    "               if (n.startswith(\"embed.\") or n.startswith(\"block.\")) and p.requires_grad]\n",
    "    head_params = [p for n,p in model.named_parameters()\n",
    "                if n.startswith(\"head.\") and p.requires_grad]\n",
    "    other_params= [p for n,p in model.named_parameters()\n",
    "                if n.startswith(\"final_ln\") and p.requires_grad]\n",
    "\n",
    "    opt = torch.optim.Adam([\n",
    "        {\"params\": enc_params,   \"lr\": 1e-4, \"weight_decay\": 1e-4},   # smaller, steadier\n",
    "        {\"params\": head_params,  \"lr\": 3e-3, \"weight_decay\": 0.0},    # freer head to grow margin, higher LR, low/zero wd\n",
    "        {\"params\": other_params, \"lr\": 3e-3, \"weight_decay\": 1e-4},\n",
    "    ])\n",
    "    # # ReduceLROnPlateau on the encoder\n",
    "    # sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     opt, mode=\"min\", factor=0.2, patience=1, threshold=1e-4\n",
    "    # )\n",
    "\n",
    "    wait = 0\n",
    "    for e in range(warm_epochs+1, epochs+1):\n",
    "        model.train()\n",
    "        # simple mini-batch loop\n",
    "        perm = torch.randperm(N, device=device) # returns a random permutation of integers from 0 to n - 1\n",
    "        total_loss = 0.0\n",
    "        for i in range(0, N, batch_size):\n",
    "            idx = perm[i:i+batch_size]\n",
    "            xb, mb, yb = Xtr[idx], Mtr[idx], ytr[idx]\n",
    "            opt.zero_grad()\n",
    "            logits, _ = model(xb, mb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            if clip: # scales all grads down uniformly so the norm equals max_norm.\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss = total_loss / N\n",
    "        val_loss, val_acc, val_brier, val_margin = evaluate_step(model, Xva, Mva, yva)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"epoch {e:03d} | train_loss={train_loss:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} | val_acc={val_acc:.3f} | \"\n",
    "                  f\"val_brier={val_brier:.4f} | val_margin={val_margin:.3f}\")\n",
    "\n",
    "        # early stopping on val loss\n",
    "        if best_val - val_loss > min_delta:\n",
    "            best_val = val_loss\n",
    "            best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience_full:\n",
    "                if verbose:\n",
    "                    print(f\"early stop at epoch {e} | best_val_loss={best_val:.4f}\")\n",
    "                break\n",
    "        \n",
    "        # # at the end of each epoch (using val_loss):\n",
    "        # sched.step(val_loss)\n",
    "        \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0e15b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm start epoch 001 | train_loss=0.7538 | val_loss=0.6124 | val_acc=0.750 | val_brier=0.2101 | val_margin=0.125\n",
      "Warm start epoch 002 | train_loss=0.7188 | val_loss=0.6187 | val_acc=0.750 | val_brier=0.2131 | val_margin=0.114\n",
      "Warm start epoch 003 | train_loss=0.7372 | val_loss=0.6240 | val_acc=0.750 | val_brier=0.2157 | val_margin=0.105\n",
      "early stop at epoch 3 | best_val_loss=0.6124\n",
      "epoch 006 | train_loss=0.7234 | val_loss=0.6286 | val_acc=0.750 | val_brier=0.2179 | val_margin=0.098\n",
      "epoch 007 | train_loss=0.7146 | val_loss=0.6432 | val_acc=0.750 | val_brier=0.2251 | val_margin=0.077\n",
      "epoch 008 | train_loss=0.7073 | val_loss=0.6669 | val_acc=0.750 | val_brier=0.2369 | val_margin=0.047\n",
      "epoch 009 | train_loss=0.6933 | val_loss=0.6954 | val_acc=0.500 | val_brier=0.2511 | val_margin=0.021\n",
      "early stop at epoch 9 | best_val_loss=0.6124\n",
      "TRAIN  loss=0.7419 acc=0.417 brier=0.2742 margin=0.119\n",
      "VALID  loss=0.6124 acc=0.750 brier=0.2101 margin=0.125\n"
     ]
    }
   ],
   "source": [
    "model_w = SingleHeadEncoderClassifier(cfg).to(DEVICE)\n",
    "model_w = train_encoder_warm_start(model_w, Xtr, Mtr, ytr, Xva, Mva, yva)\n",
    "\n",
    "# Final report on train + val\n",
    "tr_metrics = evaluate_step(model_w, Xtr.to(DEVICE), Mtr.to(DEVICE), ytr.to(DEVICE))\n",
    "va_metrics = evaluate_step(model_w, Xva.to(DEVICE), Mva.to(DEVICE), yva.to(DEVICE))\n",
    "print(f\"TRAIN  loss={tr_metrics[0]:.4f} acc={tr_metrics[1]:.3f} brier={tr_metrics[2]:.4f} margin={tr_metrics[3]:.3f}\")\n",
    "print(f\"VALID  loss={va_metrics[0]:.4f} acc={va_metrics[1]:.3f} brier={va_metrics[2]:.4f} margin={va_metrics[3]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71d6d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm start epoch 001 | train_loss=0.6965 | val_loss=0.5255 | val_acc=0.750 | val_brier=0.1693 | val_margin=0.126\n",
      "Warm start epoch 002 | train_loss=0.6891 | val_loss=0.5287 | val_acc=0.750 | val_brier=0.1706 | val_margin=0.122\n",
      "Warm start epoch 003 | train_loss=0.6913 | val_loss=0.5315 | val_acc=0.750 | val_brier=0.1719 | val_margin=0.118\n",
      "early stop at epoch 3 | best_val_loss=0.5255\n",
      "epoch 006 | train_loss=0.6909 | val_loss=0.5421 | val_acc=0.750 | val_brier=0.1765 | val_margin=0.103\n",
      "epoch 007 | train_loss=0.6722 | val_loss=0.5571 | val_acc=0.750 | val_brier=0.1834 | val_margin=0.085\n",
      "epoch 008 | train_loss=0.6532 | val_loss=0.5729 | val_acc=0.750 | val_brier=0.1908 | val_margin=0.066\n",
      "epoch 009 | train_loss=0.6514 | val_loss=0.5886 | val_acc=1.000 | val_brier=0.1983 | val_margin=0.057\n",
      "early stop at epoch 9 | best_val_loss=0.5255\n",
      "TRAIN  loss=0.6900 acc=0.500 brier=0.2485 margin=0.057\n",
      "VALID  loss=0.5255 acc=0.750 brier=0.1693 margin=0.126\n"
     ]
    }
   ],
   "source": [
    "model2_w = SingleHeadEncoderClassifier(cfg2).to(DEVICE)\n",
    "model2_w = train_encoder_warm_start(model2_w, Xtr, Mtr, ytr, Xva, Mva, yva)\n",
    "\n",
    "# Final report on train + val\n",
    "tr_metrics = evaluate_step(model2_w, Xtr.to(DEVICE), Mtr.to(DEVICE), ytr.to(DEVICE))\n",
    "va_metrics = evaluate_step(model2_w, Xva.to(DEVICE), Mva.to(DEVICE), yva.to(DEVICE))\n",
    "print(f\"TRAIN  loss={tr_metrics[0]:.4f} acc={tr_metrics[1]:.3f} brier={tr_metrics[2]:.4f} margin={tr_metrics[3]:.3f}\")\n",
    "print(f\"VALID  loss={va_metrics[0]:.4f} acc={va_metrics[1]:.3f} brier={va_metrics[2]:.4f} margin={va_metrics[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b39cb",
   "metadata": {},
   "source": [
    "Monitor: Brier + margin; if margin ↑ but Brier ↑ too, you’re becoming confidently wrong → back off head LR a touch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252aad2",
   "metadata": {},
   "source": [
    "Plateau schedulers are brittle on tiny, noisy validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representation_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
