{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8baa47e6",
   "metadata": {},
   "source": [
    "# Contrastive Learning (SimCLR/InfoNCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795a4e25",
   "metadata": {},
   "source": [
    "Two-crop pipeline: two stochastic views of the same sequence (positives).\n",
    "\n",
    "Projection head (MLP): improves contrastive training stability/quality (SimCLR finding).\n",
    "\n",
    "NT-Xent / InfoNCE loss with temperature τ and cosine similarities.\n",
    "\n",
    "Tiny eval: in-batch k-NN / retrieval sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712f34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc444a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn, torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent(z1: torch.Tensor, z2: torch.Tensor, tau: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    z1, z2: [B, D], L2-normalized.\n",
    "    Returns scalar loss (average over 2B positives).\n",
    "    \"\"\"\n",
    "    B = z1.size(0)\n",
    "    z = torch.cat([z1, z2], dim=0)              # [2B, D]\n",
    "    # Similarity matrix (cosine) scaled by temperature\n",
    "    sim = z @ z.t()                              # cosine since z's are normalized -> [2B, 2B]\n",
    "    # mask self-similarity\n",
    "    diag = torch.eye(2*B, device=z.device, dtype=torch.bool)\n",
    "    sim = sim / tau\n",
    "    sim = sim - 1e9 * diag                       # remove self-pairs\n",
    "\n",
    "    # positives: (i <-> i+B) and (i+B <-> i)\n",
    "    # each anchor sees 2B−2 negatives\n",
    "    targets = torch.cat([torch.arange(B, 2*B), torch.arange(0, B)], dim=0).to(z.device)  # [2B]\n",
    "    # Cross-entropy over rows (softmax over all 2B-1 others)\n",
    "    loss = F.cross_entropy(sim, targets)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43269d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSView:\n",
    "    def __init__(self, jitter_std=0.02, scale_min=0.9, scale_max=1.1, cutout_p=0.3, cutout_len=12):\n",
    "        self.jitter_std = jitter_std\n",
    "        self.scale_min = scale_min\n",
    "        self.scale_max = scale_max\n",
    "        self.cutout_p = cutout_p\n",
    "        self.cutout_len = cutout_len\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):   # x: [T, C]\n",
    "        # jitter\n",
    "        x = x + torch.randn_like(x) * self.jitter_std\n",
    "        # per-channel scaling\n",
    "        scales = torch.empty(x.size(1), device=x.device).uniform_(self.scale_min, self.scale_max)\n",
    "        x = x * scales\n",
    "        # cutout (time masking) — zeros a contiguous block\n",
    "        if torch.rand(()) < self.cutout_p and x.size(0) > self.cutout_len:\n",
    "            start = int(torch.randint(0, x.size(0) - self.cutout_len + 1, (1,)))\n",
    "            x[start:start+self.cutout_len] = 0.0\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d21d7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TwoCropTSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Time-series two-crop dataset.\n",
    "    X: [N, T, C] (float)\n",
    "    M: [N, T] bool pad mask (True=PAD). Pass None if no padding.\n",
    "    view: callable that applies augmentations to a [T, C] tensor and returns [T, C]\n",
    "    crop_len: fixed crop window length in timesteps\n",
    "    pad_to_crop_len: if valid length < crop_len, right-pad with zeros and set mask=True on padded tail\n",
    "    \"\"\"\n",
    "    def __init__(self, X: torch.Tensor, M: torch.Tensor | None, view, *,\n",
    "                 crop_len: int = 128, pad_to_crop_len: bool = True):\n",
    "        super().__init__()\n",
    "        assert X.ndim == 3, \"X must be [N,T,C]\"\n",
    "        self.X = X.float()\n",
    "        self.M = M if M is None else M.bool()\n",
    "        self.view = view\n",
    "        self.crop_len = crop_len\n",
    "        self.pad_to_crop_len = pad_to_crop_len\n",
    "\n",
    "    def __len__(self): return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = self.X[i]                         # [T, C]\n",
    "        m = None if self.M is None else self.M[i]  # [T] bool (True=PAD)\n",
    "\n",
    "        x1, m1 = self._crop_once(x, m)\n",
    "        x2, m2 = self._crop_once(x, m)\n",
    "        # return one sample [T, C]\n",
    "        return (x1, m1), (x2, m2)\n",
    "\n",
    "    def _crop_once(self, x: torch.Tensor, m: torch.Tensor | None):\n",
    "        T = x.size(0)\n",
    "        if m is None:\n",
    "            # whole sequence is valid\n",
    "            valid_T = T\n",
    "            start_max = max(0, valid_T - self.crop_len)\n",
    "            start = int(torch.randint(0, start_max + 1, (1,)))\n",
    "            end = start + self.crop_len\n",
    "            sub = x[start:end] if self.crop_len <= T else x\n",
    "            if self.crop_len > T and self.pad_to_crop_len:\n",
    "                sub, pad_mask = self._right_pad(sub, self.crop_len)\n",
    "            else:\n",
    "                pad_mask = torch.zeros(sub.size(0), dtype=torch.bool, device=x.device)\n",
    "        else:\n",
    "            # m: True=PAD, so valid = ~m\n",
    "            valid_len = int((~m).sum().item())\n",
    "            if valid_len == 0:\n",
    "                # degenerate: make a single-timestep zero crop and pad\n",
    "                sub = torch.zeros((0, x.size(1)), dtype=x.dtype, device=x.device)\n",
    "                sub, pad_mask = self._right_pad(sub, self.crop_len)\n",
    "                return self.view(sub), pad_mask\n",
    "\n",
    "            w = min(valid_len, self.crop_len)\n",
    "            start_max = max(0, valid_len - w)\n",
    "            start = int(torch.randint(0, start_max + 1, (1,)))\n",
    "            end = start + w\n",
    "            # take from the *valid* prefix of length valid_len\n",
    "            sub = x[:valid_len][start:end]     # [w, C]\n",
    "\n",
    "            if w < self.crop_len and self.pad_to_crop_len:\n",
    "                sub, pad_mask = self._right_pad(sub, self.crop_len)\n",
    "            else:\n",
    "                pad_mask = torch.zeros(sub.size(0), dtype=torch.bool, device=x.device)\n",
    "\n",
    "        # apply view (augmentations) in [T, C] then return sub + mask\n",
    "        sub = self.view(sub) if self.view is not None else sub\n",
    "        return sub, pad_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def _right_pad(sub: torch.Tensor, target_len: int):\n",
    "        \"\"\"Right-pad sub [t,C] to target_len with zeros; return padded sub and pad mask [target_len].\"\"\"\n",
    "        t, C = sub.size(0), sub.size(1) if sub.ndim == 2 else (sub.size(0), 1)\n",
    "        if t == target_len:\n",
    "            pad_mask = torch.zeros(t, dtype=torch.bool, device=sub.device)\n",
    "            return sub, pad_mask\n",
    "        pad = torch.zeros((target_len - t, sub.size(1)), dtype=sub.dtype, device=sub.device)\n",
    "        out = torch.cat([sub, pad], dim=0)\n",
    "        mask = torch.zeros(target_len, dtype=torch.bool, device=sub.device)\n",
    "        mask[t:] = True  # True=PAD\n",
    "        return out, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186255ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_two_way(z1, z2, tau=0.2):\n",
    "    # z1,z2: [B,D], MUST be L2-normalized along dim=-1\n",
    "    sim = (z1 @ z2.t()) / tau           # [B,B]\n",
    "    y = torch.arange(z1.size(0), device=z1.device)\n",
    "    # Each anchor sees only cross-view negatives (B−1 per anchor)\n",
    "    return 0.5 * (F.cross_entropy(sim, y) + F.cross_entropy(sim.t(), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a731c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive(model: nn.Module,loader, *,\n",
    "                      epochs=20, lr=3e-4, tau=0.1, device=None):\n",
    "    device = device or (torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for (ids1, m1), (ids2, m2) in loader:\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            ids1, m1 = ids1.to(device), m1.to(device)\n",
    "            ids2, m2 = ids2.to(device), m2.to(device)\n",
    "\n",
    "            z1 = model.encode(ids1)              # [B,d]\n",
    "            z2 = model.encode(ids2)              # [B,d]\n",
    "            loss = nt_xent(z1, z2, tau=tau)\n",
    "            # loss = info_nce_two_way(z1, z2, tau=tau)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            g = sum((p.grad is not None and p.grad.abs().sum().item()) for p in model.parameters())\n",
    "            assert g > 0, \"no gradients flowed\"\n",
    "            optim.step()\n",
    "            total += loss.item() * ids1.size(0)\n",
    "\n",
    "        avg = total / len(loader.dataset)\n",
    "        with torch.no_grad():\n",
    "            # simple health checks\n",
    "            z = torch.cat([z1, z2], 0)\n",
    "            std = z.float().std(dim=0).mean().item()\n",
    "\n",
    "            # intra-branch cosine structure (should be diag >> offdiag)\n",
    "            sim_intra = (z1 @ z1.t()).float()\n",
    "            B = sim_intra.size(0)\n",
    "            diag = sim_intra.diag().mean().item()\n",
    "            offd = (sim_intra.sum() - sim_intra.diag().sum()) / max(1, (B*B - B))\n",
    "            # cross-branch diag/offdiag for the actual loss logits\n",
    "            sim_cross = (z1 @ z2.t()).float()\n",
    "            diag_x = sim_cross.diag().mean().item()\n",
    "            offd_x = (sim_cross.sum() - sim_cross.diag().sum()) / max(1, (B*B - B))\n",
    "        print(f\"[epoch {ep:03d}] loss={avg:.4f} | z-std={std:.3f} |\"\n",
    "              f\"intra diag/off={diag:.3f}/{offd:.3f} | cross diag/off={diag_x:.3f}/{offd_x:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed548a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import numpy as np\n",
    "from src.encoder_classifier_wrapper import EncoderClassifier, LinearFrontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4869f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.synthetic_data import synth_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "268da24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, road, wthr, t = synth_trips(N=2000, T=128, use_accel=False, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1d18c888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 128, 1]),\n",
       " torch.Size([2000]),\n",
       " torch.Size([2000]),\n",
       " torch.Size([128]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, road.shape, wthr.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da9c4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mha_block import SDPAMHA, PreLNEncoderBlockSDPA, ClippedRelPosBias, SinusoidalPositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "000b190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = SinusoidalPositionalEncoding(d_model=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6d61cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build attention block\n",
    "def make_block(d_model):\n",
    "    attn = SDPAMHA(d_model=d_model, num_heads=4, p_drop=0.1, use_rope=False, rel_bias=None)\n",
    "    return PreLNEncoderBlockSDPA(d_model, attn=attn, ff_mult=4, p_drop=0.1, norm=\"ln\", resid_mode=\"plain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9f07e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontend = LinearFrontend(in_channels=1, d_model=64)  # C=1 (speed) or 2 (speed+accel)\n",
    "model = EncoderClassifier(\n",
    "    d_model=64, num_layers=2, block_ctor=make_block,\n",
    "    pool=\"mean\", posenc = pos,\n",
    "    final_norm=\"ln\", final_norm_pos=\"post_pool\", proj_dim=64,\n",
    "    frontend=frontend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9bea2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = TSView()\n",
    "ds = TwoCropTSDataset(X, M=None, view=view, crop_len=64)\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=256, shuffle=True, drop_last=True)\n",
    "ds.__getitem__(0)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4c93e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001] loss=4.1874 | z-std=0.119 |intra diag/off=1.000/0.023 | cross diag/off=0.790/0.024\n",
      "[epoch 002] loss=4.1895 | z-std=0.118 |intra diag/off=1.000/0.058 | cross diag/off=0.789/0.054\n",
      "[epoch 003] loss=4.1477 | z-std=0.119 |intra diag/off=1.000/0.034 | cross diag/off=0.798/0.027\n",
      "[epoch 004] loss=4.1278 | z-std=0.119 |intra diag/off=1.000/0.025 | cross diag/off=0.795/0.024\n",
      "[epoch 005] loss=4.1785 | z-std=0.119 |intra diag/off=1.000/0.017 | cross diag/off=0.790/0.020\n",
      "[epoch 006] loss=4.1449 | z-std=0.120 |intra diag/off=1.000/0.008 | cross diag/off=0.793/0.007\n",
      "[epoch 007] loss=4.2068 | z-std=0.120 |intra diag/off=1.000/0.017 | cross diag/off=0.779/0.017\n",
      "[epoch 008] loss=4.1541 | z-std=0.118 |intra diag/off=1.000/0.052 | cross diag/off=0.767/0.044\n",
      "[epoch 009] loss=4.1274 | z-std=0.120 |intra diag/off=1.000/0.017 | cross diag/off=0.774/0.016\n",
      "[epoch 010] loss=4.1487 | z-std=0.118 |intra diag/off=1.000/0.052 | cross diag/off=0.772/0.054\n",
      "[epoch 011] loss=4.1197 | z-std=0.119 |intra diag/off=1.000/0.023 | cross diag/off=0.812/0.025\n",
      "[epoch 012] loss=4.1533 | z-std=0.119 |intra diag/off=1.000/0.033 | cross diag/off=0.779/0.032\n",
      "[epoch 013] loss=4.1236 | z-std=0.119 |intra diag/off=1.000/0.020 | cross diag/off=0.774/0.018\n",
      "[epoch 014] loss=4.1371 | z-std=0.119 |intra diag/off=1.000/0.027 | cross diag/off=0.789/0.028\n",
      "[epoch 015] loss=4.1526 | z-std=0.119 |intra diag/off=1.000/0.027 | cross diag/off=0.780/0.028\n",
      "[epoch 016] loss=4.1243 | z-std=0.119 |intra diag/off=1.000/0.018 | cross diag/off=0.789/0.020\n",
      "[epoch 017] loss=4.1334 | z-std=0.120 |intra diag/off=1.000/0.013 | cross diag/off=0.763/0.014\n",
      "[epoch 018] loss=4.1445 | z-std=0.120 |intra diag/off=1.000/0.012 | cross diag/off=0.775/0.013\n",
      "[epoch 019] loss=4.1277 | z-std=0.119 |intra diag/off=1.000/0.034 | cross diag/off=0.769/0.035\n",
      "[epoch 020] loss=4.1322 | z-std=0.119 |intra diag/off=1.000/0.018 | cross diag/off=0.764/0.020\n"
     ]
    }
   ],
   "source": [
    "train_contrastive(model=model, loader=loader, tau=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a8d3dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "dev = torch.device(\"mps\")\n",
    "(x1, m1), (x2, m2), *_ = next(iter(loader))\n",
    "x1, x2 = x1.to(dev), x2.to(dev)\n",
    "z1 = model.encode(x1, mask=m1.to(dev))\n",
    "z2 = model.encode(x2, mask=m2.to(dev))\n",
    "assert z1.requires_grad and z2.requires_grad, \"encode() is producing no-grad tensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ba2dcf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ(x1,x2): 0.6974043846130371\n"
     ]
    }
   ],
   "source": [
    "print(\"Δ(x1,x2):\", (x1 - x2).abs().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2fc357e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frontend std: 0.7535977363586426\n"
     ]
    }
   ],
   "source": [
    "# 1) frontend signal\n",
    "h1f, _ = model.frontend(x1, m1)  # [B,T,D]\n",
    "h2f, _ = model.frontend(x2, m2)\n",
    "print(\"frontend std:\", h1f.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "438bec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after block std: 0.9703962802886963\n"
     ]
    }
   ],
   "source": [
    "# 2) after first block (no masks for fixed crops)\n",
    "h1 = model.layers[0](h1f)\n",
    "h2 = model.layers[0](h2f)\n",
    "print(\"after block std:\", h1.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a1225720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooled std: 0.7788299322128296\n"
     ]
    }
   ],
   "source": [
    "# 3) pooled before proj\n",
    "def masked_mean(x, pad_mask):\n",
    "    return x.mean(1) if pad_mask is None else (x * (~pad_mask).float().unsqueeze(-1)).sum(1) / ((~pad_mask).float().sum(1, keepdim=True).clamp_min(1.0))\n",
    "\n",
    "h1p = masked_mean(h1, None)\n",
    "h2p = masked_mean(h2, None)\n",
    "print(\"pooled std:\", h1p.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cfa3b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj pre-norm std: 0.14979314804077148\n"
     ]
    }
   ],
   "source": [
    "# 4) projection (pre-norm)\n",
    "z1p = model.proj(h1p)\n",
    "z2p = model.proj(h2p)\n",
    "print(\"proj pre-norm std:\", z1p.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b28eaaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos diag mean: 0.9398491978645325 offdiag mean: 0.5329511165618896\n"
     ]
    }
   ],
   "source": [
    "# 5) final norm + cosine stats\n",
    "z1 = F.normalize(z1p, dim=-1)\n",
    "z2 = F.normalize(z2p, dim=-1)\n",
    "sim = z1 @ z2.T\n",
    "B = z1.size(0)\n",
    "diag = sim.diag().mean().item()\n",
    "offd = (sim.sum() - sim.diag().sum()) / (B*B - B)\n",
    "print(\"cos diag mean:\", diag, \"offdiag mean:\", offd.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc50e545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw cos diag: 1.0 raw cos offdiag: 0.5339733362197876\n"
     ]
    }
   ],
   "source": [
    "# 1) Cosines BEFORE normalization\n",
    "sim_raw = torch.nn.functional.cosine_similarity(\n",
    "    z1p.unsqueeze(1), z1p.unsqueeze(0), dim=-1\n",
    ")  # [B,B]\n",
    "B = sim_raw.size(0)\n",
    "print(\"raw cos diag:\", sim_raw.diag().mean().item(),\n",
    "      \"raw cos offdiag:\", ((sim_raw.sum()-sim_raw.diag().sum())/(B*B-B)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "535cec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm cos diag: 1.0 norm cos offdiag: 0.5339733362197876\n"
     ]
    }
   ],
   "source": [
    "# 2) Cosines AFTER normalization you use in loss\n",
    "sim_norm = (z1 @ z1.t())  # if you normalize correctly, offdiag should drop vs diag\n",
    "print(\"norm cos diag:\", sim_norm.diag().mean().item(),\n",
    "      \"norm cos offdiag:\", ((sim_norm.sum()-sim_norm.diag().sum())/(B*B-B)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b7285762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 params have grads\n"
     ]
    }
   ],
   "source": [
    "# grads flow?\n",
    "loss = nt_xent(z1, z2, tau=0.2)\n",
    "loss.backward()\n",
    "print(sum(int(p.grad is not None) for p in model.parameters()), \"params have grads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a9c28d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra z1 diag: 1.0 offdiag: 0.5339733362197876\n"
     ]
    }
   ],
   "source": [
    "# batch similarity structure inside each branch (should NOT be ~all ones)\n",
    "sim_intra = (z1 @ z1.t()).detach()\n",
    "print(\"intra z1 diag:\", sim_intra.diag().mean().item(),\n",
    "      \"offdiag:\", ((sim_intra.sum()-sim_intra.diag().sum())/(B*B-B)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b438afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos diag mean: 0.9398491978645325 offdiag mean: tensor(0.5330, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    B = z1.size(0)\n",
    "    s = (z1 @ z2.t())\n",
    "    print(\"cos diag mean:\", s.diag().mean().item(), \"offdiag mean:\", (s.sum() - s.diag().sum())/ (B*B-B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f553c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    z = head(h) for contrastive training.\n",
    "    SimCLR-style: MLP -> (norm) -> nonlinearity -> Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim: int, hid: int = 256, out_dim: int = 128, use_ln: bool = True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, hid)]\n",
    "        if use_ln: layers += [nn.LayerNorm(hid)]\n",
    "        layers += [nn.ReLU(), nn.Linear(hid, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, h):           # h: [B, D]\n",
    "        z = self.net(h)             # [B, out_dim]\n",
    "        z = F.normalize(z, dim=-1)  # L2-normalize for cosine/InfoNCE\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a1cfd68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projector with BatchNorm\n",
    "class SimCLRProjector(nn.Module):\n",
    "    def __init__(self, d, p):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d, d, bias=False), nn.BatchNorm1d(d), nn.ReLU(inplace=True),\n",
    "            nn.Linear(d, p, bias=False), nn.BatchNorm1d(p, affine=False)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "717964a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = ProjectionHead(in_dim=64, out_dim=64)\n",
    "model2 = EncoderClassifier(\n",
    "    d_model=64, num_layers=2, block_ctor=make_block,\n",
    "    pool=\"mean\", posenc = pos,\n",
    "    final_norm=\"ln\", final_norm_pos=\"post_pool\", proj_dim=64,\n",
    "    frontend=frontend,\n",
    "    projector=projector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "687ddeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001] loss=4.8491 | z-std=0.094 |intra diag/off=1.000/0.322 | cross diag/off=0.958/0.321\n",
      "[epoch 002] loss=4.6115 | z-std=0.109 |intra diag/off=1.000/0.097 | cross diag/off=0.910/0.095\n",
      "[epoch 003] loss=4.5561 | z-std=0.106 |intra diag/off=1.000/0.123 | cross diag/off=0.917/0.131\n",
      "[epoch 004] loss=4.4737 | z-std=0.111 |intra diag/off=1.000/0.058 | cross diag/off=0.910/0.058\n",
      "[epoch 005] loss=4.4256 | z-std=0.114 |intra diag/off=1.000/0.054 | cross diag/off=0.857/0.056\n",
      "[epoch 006] loss=4.3676 | z-std=0.114 |intra diag/off=1.000/0.059 | cross diag/off=0.875/0.057\n",
      "[epoch 007] loss=4.3644 | z-std=0.115 |intra diag/off=1.000/0.042 | cross diag/off=0.844/0.041\n",
      "[epoch 008] loss=4.3317 | z-std=0.116 |intra diag/off=1.000/0.028 | cross diag/off=0.865/0.029\n",
      "[epoch 009] loss=4.3087 | z-std=0.114 |intra diag/off=1.000/0.046 | cross diag/off=0.874/0.051\n",
      "[epoch 010] loss=4.3310 | z-std=0.117 |intra diag/off=1.000/0.019 | cross diag/off=0.848/0.021\n",
      "[epoch 011] loss=4.3042 | z-std=0.116 |intra diag/off=1.000/0.044 | cross diag/off=0.833/0.043\n",
      "[epoch 012] loss=4.2726 | z-std=0.117 |intra diag/off=1.000/0.034 | cross diag/off=0.845/0.029\n",
      "[epoch 013] loss=4.2887 | z-std=0.116 |intra diag/off=1.000/0.056 | cross diag/off=0.828/0.055\n",
      "[epoch 014] loss=4.2615 | z-std=0.118 |intra diag/off=1.000/0.020 | cross diag/off=0.812/0.022\n",
      "[epoch 015] loss=4.2344 | z-std=0.117 |intra diag/off=1.000/0.034 | cross diag/off=0.806/0.036\n",
      "[epoch 016] loss=4.2332 | z-std=0.117 |intra diag/off=1.000/0.050 | cross diag/off=0.798/0.046\n",
      "[epoch 017] loss=4.2695 | z-std=0.116 |intra diag/off=1.000/0.052 | cross diag/off=0.793/0.052\n",
      "[epoch 018] loss=4.1878 | z-std=0.117 |intra diag/off=1.000/0.061 | cross diag/off=0.766/0.055\n",
      "[epoch 019] loss=4.2345 | z-std=0.117 |intra diag/off=1.000/0.044 | cross diag/off=0.798/0.044\n",
      "[epoch 020] loss=4.2560 | z-std=0.117 |intra diag/off=1.000/0.050 | cross diag/off=0.804/0.049\n"
     ]
    }
   ],
   "source": [
    "train_contrastive(model=model2, loader=loader, tau=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "eac1bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector_bn = SimCLRProjector(d=64, p=64)\n",
    "model3 = EncoderClassifier(\n",
    "    d_model=64, num_layers=2, block_ctor=make_block,\n",
    "    pool=\"mean\", posenc = pos,\n",
    "    final_norm=\"ln\", final_norm_pos=\"post_pool\", proj_dim=64,\n",
    "    frontend=frontend,\n",
    "    projector=projector_bn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6cebf702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001] loss=4.4894 | z-std=0.124 |intra diag/off=1.000/0.010 | cross diag/off=0.822/0.011\n",
      "[epoch 002] loss=4.3682 | z-std=0.124 |intra diag/off=1.000/0.008 | cross diag/off=0.778/0.010\n",
      "[epoch 003] loss=4.3462 | z-std=0.124 |intra diag/off=1.000/0.011 | cross diag/off=0.802/0.011\n",
      "[epoch 004] loss=4.3184 | z-std=0.124 |intra diag/off=1.000/0.007 | cross diag/off=0.789/0.008\n",
      "[epoch 005] loss=4.2859 | z-std=0.124 |intra diag/off=1.000/0.007 | cross diag/off=0.789/0.008\n",
      "[epoch 006] loss=4.2615 | z-std=0.124 |intra diag/off=1.000/0.008 | cross diag/off=0.799/0.009\n",
      "[epoch 007] loss=4.2587 | z-std=0.124 |intra diag/off=1.000/0.005 | cross diag/off=0.793/0.006\n",
      "[epoch 008] loss=4.2579 | z-std=0.124 |intra diag/off=1.000/0.005 | cross diag/off=0.764/0.005\n",
      "[epoch 009] loss=4.2714 | z-std=0.124 |intra diag/off=1.000/0.001 | cross diag/off=0.767/0.003\n",
      "[epoch 010] loss=4.2191 | z-std=0.124 |intra diag/off=1.000/0.002 | cross diag/off=0.756/0.003\n",
      "[epoch 011] loss=4.2061 | z-std=0.124 |intra diag/off=1.000/0.004 | cross diag/off=0.732/0.004\n",
      "[epoch 012] loss=4.1873 | z-std=0.125 |intra diag/off=1.000/-0.001 | cross diag/off=0.775/0.000\n",
      "[epoch 013] loss=4.1943 | z-std=0.125 |intra diag/off=1.000/0.000 | cross diag/off=0.778/0.001\n",
      "[epoch 014] loss=4.2287 | z-std=0.125 |intra diag/off=1.000/-0.002 | cross diag/off=0.743/-0.001\n",
      "[epoch 015] loss=4.1913 | z-std=0.125 |intra diag/off=1.000/-0.001 | cross diag/off=0.748/0.000\n",
      "[epoch 016] loss=4.1646 | z-std=0.125 |intra diag/off=1.000/0.000 | cross diag/off=0.768/0.001\n",
      "[epoch 017] loss=4.1870 | z-std=0.125 |intra diag/off=1.000/-0.000 | cross diag/off=0.752/0.001\n",
      "[epoch 018] loss=4.1744 | z-std=0.125 |intra diag/off=1.000/-0.000 | cross diag/off=0.741/0.001\n",
      "[epoch 019] loss=4.1460 | z-std=0.125 |intra diag/off=1.000/-0.001 | cross diag/off=0.747/0.000\n",
      "[epoch 020] loss=4.1759 | z-std=0.125 |intra diag/off=1.000/0.000 | cross diag/off=0.776/0.000\n"
     ]
    }
   ],
   "source": [
    "train_contrastive(model=model3, loader=loader, tau=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3ada2e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001] loss=4.1835 | z-std=0.125 |intra diag/off=1.000/0.001 | cross diag/off=0.828/0.001\n",
      "[epoch 002] loss=4.2480 | z-std=0.125 |intra diag/off=1.000/0.001 | cross diag/off=0.822/0.001\n",
      "[epoch 003] loss=4.2483 | z-std=0.124 |intra diag/off=1.000/0.005 | cross diag/off=0.819/0.007\n",
      "[epoch 004] loss=4.1947 | z-std=0.124 |intra diag/off=1.000/0.008 | cross diag/off=0.845/0.007\n",
      "[epoch 005] loss=4.2182 | z-std=0.124 |intra diag/off=1.000/0.008 | cross diag/off=0.821/0.009\n",
      "[epoch 006] loss=4.1470 | z-std=0.124 |intra diag/off=1.000/0.011 | cross diag/off=0.837/0.011\n",
      "[epoch 007] loss=4.1523 | z-std=0.124 |intra diag/off=1.000/0.011 | cross diag/off=0.829/0.012\n",
      "[epoch 008] loss=4.1179 | z-std=0.124 |intra diag/off=1.000/0.007 | cross diag/off=0.838/0.009\n",
      "[epoch 009] loss=4.1939 | z-std=0.124 |intra diag/off=1.000/0.012 | cross diag/off=0.835/0.014\n",
      "[epoch 010] loss=4.1107 | z-std=0.124 |intra diag/off=1.000/0.012 | cross diag/off=0.863/0.014\n",
      "[epoch 011] loss=4.1881 | z-std=0.123 |intra diag/off=1.000/0.018 | cross diag/off=0.825/0.019\n",
      "[epoch 012] loss=4.1300 | z-std=0.124 |intra diag/off=1.000/0.011 | cross diag/off=0.837/0.013\n",
      "[epoch 013] loss=4.0653 | z-std=0.123 |intra diag/off=1.000/0.020 | cross diag/off=0.856/0.022\n",
      "[epoch 014] loss=4.1038 | z-std=0.123 |intra diag/off=1.000/0.018 | cross diag/off=0.847/0.018\n",
      "[epoch 015] loss=4.0935 | z-std=0.123 |intra diag/off=1.000/0.017 | cross diag/off=0.858/0.018\n",
      "[epoch 016] loss=4.1123 | z-std=0.123 |intra diag/off=1.000/0.017 | cross diag/off=0.844/0.018\n",
      "[epoch 017] loss=4.1479 | z-std=0.124 |intra diag/off=1.000/0.016 | cross diag/off=0.832/0.016\n",
      "[epoch 018] loss=4.1268 | z-std=0.123 |intra diag/off=1.000/0.018 | cross diag/off=0.840/0.019\n",
      "[epoch 019] loss=4.1183 | z-std=0.124 |intra diag/off=1.000/0.012 | cross diag/off=0.847/0.011\n",
      "[epoch 020] loss=4.1009 | z-std=0.124 |intra diag/off=1.000/0.015 | cross diag/off=0.849/0.015\n"
     ]
    }
   ],
   "source": [
    "train_contrastive(model=model3, loader=loader, tau=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35748e28",
   "metadata": {},
   "source": [
    "z-std ≈ 0.124 → no collapse.\n",
    "\n",
    "intra off ≈ 0.015 and cross off ≈ 0.015 → negatives are well spread (uniformity 👍).\n",
    "\n",
    "cross diag ≈ 0.849 → positives are meaningfully closer than negatives (alignment 👍)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82388d2",
   "metadata": {},
   "source": [
    "## Freeze & probe (road / weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c187b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method EncoderClassifier.features of EncoderClassifier(\n",
       "  (frontend): LinearFrontend(\n",
       "    (proj): Linear(in_features=1, out_features=64, bias=True)\n",
       "  )\n",
       "  (posenc): SinusoidalPositionalEncoding()\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x PreLNEncoderBlockSDPA(\n",
       "      (attn): SDPAMHA(\n",
       "        (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (o): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (proj): SimCLRProjector(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "48f2cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.eval()\n",
    "enc = model3.features  # or a wrapper that returns pooled pre-projection h\n",
    "with torch.no_grad():\n",
    "    Z = enc(X.to(dev))   # [N,D]\n",
    "# simple linear probes (logreg) for road (3) & weather (2)\n",
    "clf_road = torch.nn.Linear(Z.size(1), 3).to(dev)\n",
    "clf_wthr = torch.nn.Linear(Z.size(1), 2).to(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "547b41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 64])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5cf9b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_idx(N, val=0.2, seed=0): # train test split\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    perm = torch.randperm(N, generator=g)\n",
    "    n_val = int(N * val)\n",
    "    return perm[n_val:], perm[:n_val]   # train_idx, val_idx\n",
    "\n",
    "def train_linear_probe(Z, y, clf, *, epochs=200, lr=1e-2, wd=0.0, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    Z = Z.to(device)\n",
    "    y = y.to(device).long()\n",
    "    W = clf.to(device)\n",
    "    opt = torch.optim.AdamW(W.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss = F.cross_entropy(W(Z), y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return W\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(W, Z, y, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    logits = W(Z.to(device))\n",
    "    pred = logits.argmax(dim=-1).cpu()\n",
    "    return (pred == y.cpu().long()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "355c25db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = next(model3.parameters()).device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "acb9ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "train_idx, val_idx = split_idx(Z.size(0), val=0.2, seed=42)\n",
    "Ztr, Zva = Z[train_idx], Z[val_idx]\n",
    "road_tr, road_va = road[train_idx], road[val_idx]\n",
    "wthr_tr, wthr_va = wthr[train_idx], wthr[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2fe64fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train probes\n",
    "W_road = train_linear_probe(Ztr, road_tr, clf_road, epochs=200, lr=1e-2, wd=1e-4, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "38c63561",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_wthr = train_linear_probe(Ztr, wthr_tr, clf_wthr, epochs=200, lr=1e-2, wd=1e-4, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0de1464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear probe – road: 0.890, weather: 0.600\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "acc_road = accuracy(W_road, Zva, road_va, device=device)\n",
    "acc_wthr = accuracy(W_wthr, Zva, wthr_va, device=device)\n",
    "print(f\"Linear probe – road: {acc_road:.3f}, weather: {acc_wthr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representation_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
