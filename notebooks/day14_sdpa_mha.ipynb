{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02450227",
   "metadata": {},
   "source": [
    "# Drop-in SDPA MHA with optional RoPE + RelBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6631fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6f439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn, torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d98d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- (A) tiny RoPE helper -----\n",
    "def apply_rope(q, k, base=10000.0):\n",
    "    # q,k: [B,H,T,Dh]; split half-dims\n",
    "    Dh = q.size(-1); assert Dh % 2 == 0, \"RoPE needs even head dim\"\n",
    "    half = Dh // 2\n",
    "    q1, q2 = q[..., :half], q[..., half:]\n",
    "    k1, k2 = k[..., :half], k[..., half:]\n",
    "    T = q.size(-2)\n",
    "    device = q.device\n",
    "    dtype = q.dtype\n",
    "\n",
    "    pos = torch.arange(T, device=device, dtype=dtype)[:, None]                    # [T,1]\n",
    "    inv_freqs = torch.exp(-math.log(base) * (torch.arange(0, half, device=device, dtype=dtype) / half))[None, :]   # [1, half]\n",
    "    ang = pos * inv_freqs                                                    # [T,half]\n",
    "    sin, cos = torch.sin(ang), torch.cos(ang)                                              # [T,half]\n",
    "    # broadcast to [B,H,T,half]\n",
    "    sin = sin[None, None, :, :]; cos = cos[None, None, :, :]\n",
    "\n",
    "    # rotate (x1, x2) -> (x1*cos - x2*sin, x2*cos + x1*sin)\n",
    "    def rot(x1, x2):\n",
    "        return x1 * cos - x2 * sin, x2 * cos + x1 * sin\n",
    "\n",
    "    q1r, q2r = rot(q1, q2); k1r, k2r = rot(k1, k2) # [B, H, T, half]\n",
    "    q = torch.cat([q1r, q2r], dim=-1)\n",
    "    k = torch.cat([k1r, k2r], dim=-1)\n",
    "    return q, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c21c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- (B) clipped T5-style per-head relative bias -----\n",
    "class ClippedRelPosBias(nn.Module):\n",
    "    def __init__(self, num_heads, max_rel=128):\n",
    "        super().__init__()\n",
    "        self.max_rel = max_rel\n",
    "        self.table = nn.Parameter(torch.zeros(num_heads, 2*max_rel - 1))  # [H, 2R-1]\n",
    "    def forward(self, T, device=None):\n",
    "        device = device or self.table.device\n",
    "        q = torch.arange(T, device=device)[:, None] # [T,1]  (query indices i)\n",
    "        k = torch.arange(T, device=device)[None, :] # [1, T] (key indices j)\n",
    "        rel = (k - q).clamp(-self.max_rel+1, self.max_rel-1) # [T, T]\n",
    "        idx = rel + (self.max_rel - 1)              # map to [0..2R-2]\n",
    "        return self.table[:, idx]                   # [H, T, T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a396df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_neg(dtype):\n",
    "    # Safe additive mask sentinels\n",
    "    return -1e4 if dtype in (torch.float16, torch.bfloat16) else -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87eb1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- (C) SDPA-based MHA (pre-proj qkv, optional RoPE + RelBias) -----\n",
    "class SDPAMHA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, p_drop=0.0, use_rope=False, rel_bias=None):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.h = num_heads\n",
    "        self.dh = d_model // num_heads\n",
    "        # Use chunk later to separate: fewer kernel launches, better cache locality, and lower Python/autograd overhead.\n",
    "        self.qkv = nn.Linear(d_model, 3*d_model, bias=True)\n",
    "        self.o   = nn.Linear(d_model, d_model, bias=True)\n",
    "        self.drop_p = p_drop\n",
    "        self.use_rope = use_rope\n",
    "        self.rel_bias = rel_bias  # nn.Module or None\n",
    "\n",
    "    def split_heads(self, x):  # [B,T,D] -> [B,H,T,Dh]\n",
    "        B,T,D = x.shape\n",
    "        x = x.view(B,T,self.h,self.dh).permute(0,2,1,3) # [B,T,D] -> [B, T, H, Dh] -> [B, H, T, Dh]\n",
    "        return x\n",
    "    def merge_heads(self, x):  # [B,H,T,Dh] -> [B,T,D]\n",
    "        B,H,T,Dh = x.shape\n",
    "        return x.permute(0,2,1,3).reshape(B,T,H*Dh)\n",
    "        # permute usually makes the tensor non-contiguous, .reshape() is equivalent to .contiguous().view()\n",
    "\n",
    "    def forward(self, x, pad_mask=None, causal=False):\n",
    "        # pad_mask: [B,T] bool, True=real token\n",
    "        B,T,D = x.shape\n",
    "        q,k,v = self.qkv(x).chunk(3, dim=-1)               # [B,T,D] each\n",
    "        q,k,v = self.split_heads(q), self.split_heads(k), self.split_heads(v)  # [B,H,T,Dh]\n",
    "\n",
    "        if self.use_rope:\n",
    "            q, k = apply_rope(q, k)                        # rotate Q/K in-place\n",
    "\n",
    "        # ---- Build SDPA attn_mask ----\n",
    "        # SDPA accepts:\n",
    "        #  * boolean mask: True = ALLOW attention (opposite of nn.MultiheadAttention)\n",
    "        #  * float mask: added to logits\n",
    "        attn_mask = None\n",
    "        if pad_mask is not None: # pad original dim: [B,T]\n",
    "            # Allow attending to real keys only; do NOT AND with query mask\n",
    "            m = pad_mask[:, None, None, :]   # [B,1,1,T], True = allowed keys\n",
    "            attn_mask = m  # boolean is fine when no extra bias\n",
    "        \n",
    "        # Right before calling the encoder, once per batch:\n",
    "        assert pad_mask is None or (pad_mask.sum(dim=1) > 0).all(), \"Empty sequence in batch; add CLS/UNK or drop it.\"\n",
    "\n",
    "        if self.rel_bias is not None:\n",
    "            bias = self.rel_bias(T, device=x.device)       # [H,T,T]\n",
    "            # turn everything into a FLOAT additive mask broadcastable to [B,H,T,T]\n",
    "            bias = bias.unsqueeze(0).expand(B, -1, -1, -1) # [B,H,T,T]\n",
    "            if attn_mask is not None and attn_mask.dtype == torch.bool:\n",
    "                neg = large_neg(x.dtype)\n",
    "                # convert boolean allow-mask to float additive: disallowed → a large finite negative\n",
    "                # Can't use -inf, the MPS backend turn it into nan.\n",
    "                float_mask = (~attn_mask).to(bias.dtype) * neg\n",
    "                attn_mask = float_mask + bias               # [B,H,T,T] float\n",
    "            else:\n",
    "                attn_mask = bias                            # [B,H,T,T] float\n",
    "\n",
    "        for name, t in {\"q\": q, \"k\": k, \"v\": v}.items():\n",
    "            if not torch.isfinite(t).all():\n",
    "                raise RuntimeError(f\"{name} has non-finite values\")\n",
    "\n",
    "        if attn_mask is not None and attn_mask.dtype.is_floating_point:\n",
    "            if not torch.isfinite(attn_mask[attn_mask > -1e30]).all():  # ignore our -inf sentinels\n",
    "                raise RuntimeError(\"attn_mask has non-finite (non -inf) values\")\n",
    "            \n",
    "        # ---- SDPA (handles scale, softmax, dropout, matmul) ----\n",
    "        # SDPA expects [B,H,T,Dh]; attn_mask broadcastable to [B,H,T,T]\n",
    "        out = F.scaled_dot_product_attention(\n",
    "            q, k, v,\n",
    "            attn_mask=attn_mask,\n",
    "            dropout_p=(self.drop_p if self.training else 0.0),\n",
    "            is_causal=bool(causal)\n",
    "        )                                                  # [B,H,T,Dh]\n",
    "        x = self.merge_heads(out)                          # [B,T,D]\n",
    "        x = self.o(x)                     # [B,T,D]\n",
    "        if pad_mask is not None:\n",
    "            x = x * pad_mask.unsqueeze(-1).to(x.dtype)  # zero padded query rows\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9aee0",
   "metadata": {},
   "source": [
    "# Plug SDPA MHA into Pre-LN encoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc89d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreLNEncoderBlockSDPA(nn.Module):\n",
    "    \"\"\"\n",
    "    Pre-LN Encoder block that *composes* your SDPAMHA attention module.\n",
    "    Pre-LN + residual wiring + FFN\n",
    "    x -> x + Drop( Attn( LN(x) ) )\n",
    "       -> x + Drop( FFN( LN(x) ) )\n",
    "\n",
    "    Expects:\n",
    "      - attn: a module like SDPAMHA with signature:\n",
    "              attn(x: [B,T,D], pad_mask: Optional[Bool[B,T]], causal: bool) -> [B,T,D]\n",
    "      - pad_mask: Bool[B,T], True = real token (not PAD)\n",
    "      - causal: usually False for encoders\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        *,\n",
    "        attn: nn.Module,          # <-- pass your SDPAMHA instance here\n",
    "        ff_mult: int = 4,\n",
    "        p_drop: float = 0.1,\n",
    "        norm: str = \"ln\",\n",
    "        resid_mode: str = \"plain\",  # {\"plain\",\"scaled\",\"rezero\"}\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.attn = attn                       # <-- your SDPAMHA\n",
    "        self.ln1  = make_norm(norm, d_model)\n",
    "        self.drop1 = nn.Dropout(p_drop)\n",
    "\n",
    "        self.ln2  = make_norm(norm, d_model)\n",
    "        self.ff   = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_mult * d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_mult * d_model, d_model),\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(p_drop)\n",
    "\n",
    "        self.mode = resid_mode\n",
    "        if resid_mode == \"rezero\":\n",
    "            self.g = nn.Parameter(torch.zeros(1))  # learnable gate\n",
    "        elif resid_mode == \"scaled\":\n",
    "            self.alpha = 0.5                       # constant residual scale\n",
    "\n",
    "    def _resid(self, x, h):\n",
    "        # residual add with optional scaling/gating\n",
    "        if self.mode == \"plain\":\n",
    "            return x + h\n",
    "        elif self.mode == \"scaled\":\n",
    "            return x + self.alpha * h\n",
    "        elif self.mode == \"rezero\":\n",
    "            return x + self.g * h\n",
    "        else:\n",
    "            raise ValueError(f\"unknown resid_mode={self.mode}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask: torch.Tensor | None = None, causal: bool = False):\n",
    "        \"\"\"\n",
    "        x:        [B,T,D]\n",
    "        pad_mask: Bool[B,T], True = real token (not PAD). Will be passed through to SDPAMHA.\n",
    "        causal:   usually False for encoders\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        if pad_mask is not None:\n",
    "            assert pad_mask.dtype == torch.bool and pad_mask.shape == (B, T), \"pad_mask must be Bool[B,T]\"\n",
    "\n",
    "        # --- Attention branch (Pre-LN) ---\n",
    "        a_in = self.ln1(x)\n",
    "        a_out = self.attn(a_in, pad_mask=pad_mask, causal=causal)  # expects [B,T,D] from your SDPAMHA\n",
    "        x = self._resid(x, self.drop1(a_out))\n",
    "\n",
    "        # --- FFN branch (Pre-LN) ---\n",
    "        f_in = self.ln2(x)\n",
    "        f_out = self.ff(f_in)\n",
    "        x = self._resid(x, self.drop2(f_out))\n",
    "\n",
    "        return x  # [B,T,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f00c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.text_helpers import make_tensors\n",
    "from src.encoder_classifier_wrapper import EncoderClassifier\n",
    "from src.train_utils import TrainConfig, kfold_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4278bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0）Prepare X, y, M (ids [B,T], labels [B], mask [B,T] bool)\n",
    "greeting_hard = [\n",
    "    \"good morning everyone\",\n",
    "    \"hello there my friend\",\n",
    "    \"hey buddy how are you\",\n",
    "    \"good evening folks\",\n",
    "    \"salutations from the sushi bar\",          # greeting + food word\n",
    "    \"pizza party greetings to all\",            # greeting + food word\n",
    "    \"hi from the ramen shop\",                  # greeting + food word\n",
    "    \"hello and welcome to brunch\",             # greeting + food word\n",
    "]\n",
    "food_hard = [\n",
    "    \"i love pizza\",\n",
    "    \"pasta is tasty tonight\",\n",
    "    \"fresh salad with apple\",\n",
    "    \"i like sushi a lot\",\n",
    "    \"good sandwich this morning\",              # food + greeting words\n",
    "    \"ramen is great hello world\",              # food + greeting word\n",
    "    \"eating an apple for breakfast\",\n",
    "    \"not a fan of pizza anymore\",              # negation\n",
    "]\n",
    "HARD_SUP = greeting_hard + food_hard\n",
    "HARD_LABELS = [0]*len(greeting_hard) + [1]*len(food_hard)\n",
    "X, M, y_float, y_long, stoi, itos, pad_id, cls_id = make_tensors(HARD_SUP, HARD_LABELS, min_freq=1, add_cls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54f92537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7963cc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_id, cls_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "456851ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build your attention block\n",
    "def make_block(d_model):\n",
    "    attn = SDPAMHA(d_model=d_model, num_heads=4, p_drop=0.1, use_rope=False, rel_bias=ClippedRelPosBias(4))\n",
    "    # ClippedRelPosBias(4)\n",
    "    return PreLNEncoderBlockSDPA(d_model, attn=attn, ff_mult=4, p_drop=0.1, norm=\"ln\", resid_mode=\"plain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da46184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Build the model ctor\n",
    "def make_model(vocab_size, d_model, pad_id, cls_id, num_layers=2, pool=\"mean\"):\n",
    "    return EncoderClassifier(\n",
    "        vocab_size=vocab_size, d_model=d_model, pad_id=pad_id,\n",
    "        num_layers=num_layers, block_ctor=make_block, pool=pool,\n",
    "        cls_id=cls_id, posenc=None, final_norm=\"ln\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a32718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b6278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderClassifier(\n",
       "  (embed): Embedding(57, 64, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x PreLNEncoderBlockSDPA(\n",
       "      (attn): SDPAMHA(\n",
       "        (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "        (o): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (rel_bias): ClippedRelPosBias()\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop1): Dropout(p=0.1, inplace=False)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos)\n",
    "d_model = 64\n",
    "make_model(vocab_size, d_model, pad_id, cls_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cab1cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 6]), torch.Size([1, 16, 6]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.unsqueeze(0).shape, M.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b1e09fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 64])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "X_ids = embed(X)\n",
    "X_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c24f166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.9122e-02,  3.1716e-01, -4.0687e-01,  ..., -3.4909e-01,\n",
       "           4.4481e-02,  2.4969e-01],\n",
       "         [-6.5194e-02,  2.5074e-01, -4.3719e-01,  ..., -2.8228e-01,\n",
       "          -1.4467e-02,  1.3763e-01],\n",
       "         [-3.0605e-02,  1.2488e-01, -3.9658e-01,  ..., -2.6313e-01,\n",
       "          -4.9807e-02,  1.5437e-01],\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.0762e-01, -1.1731e-01, -2.3151e-01,  ...,  1.5283e-01,\n",
       "           4.9701e-01,  1.3370e-01],\n",
       "         [-3.9643e-02, -1.9676e-01, -2.4049e-01,  ...,  9.1659e-02,\n",
       "           5.0472e-01,  5.4839e-02],\n",
       "         [ 8.1359e-02, -1.7565e-01, -2.1104e-01,  ...,  1.3653e-01,\n",
       "           4.8680e-01,  1.5607e-01],\n",
       "         [ 1.1275e-01, -9.0813e-02, -2.0965e-01,  ...,  1.4689e-01,\n",
       "           5.3510e-01,  1.6610e-01],\n",
       "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 3.5954e-01, -1.7865e-01, -9.6060e-02,  ..., -1.1635e-01,\n",
       "          -1.7653e-01, -1.6811e-01],\n",
       "         [ 2.7775e-01, -6.2724e-02, -1.2371e-01,  ..., -1.2673e-01,\n",
       "          -1.8791e-01, -2.4673e-01],\n",
       "         [ 2.0188e-01, -1.4424e-01, -7.4117e-02,  ..., -1.4592e-01,\n",
       "           4.2632e-04, -1.4890e-01],\n",
       "         [ 2.3749e-01, -9.5433e-02,  2.6052e-02,  ..., -7.2832e-02,\n",
       "          -1.4395e-01, -1.3197e-01],\n",
       "         [ 3.0724e-01, -1.6934e-01,  6.8283e-02,  ..., -3.1408e-01,\n",
       "          -1.1837e-01, -1.5017e-01],\n",
       "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7287e-01,  7.8919e-02, -1.4855e-01,  ..., -1.8504e-02,\n",
       "           3.7014e-01, -2.0134e-01],\n",
       "         [ 3.1418e-01,  7.3454e-02, -2.7329e-01,  ...,  3.5884e-02,\n",
       "           2.4569e-01, -1.9958e-01],\n",
       "         [ 1.7300e-01,  1.6438e-01, -2.7866e-01,  ..., -5.7454e-02,\n",
       "           1.5494e-01, -1.8574e-01],\n",
       "         [ 3.7348e-02,  1.1224e-01, -3.0751e-01,  ...,  1.0297e-01,\n",
       "           2.8236e-01, -1.1608e-01],\n",
       "         [-3.1873e-02,  1.2727e-01, -2.4124e-01,  ...,  9.3082e-02,\n",
       "           1.1416e-01, -1.6191e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[ 1.7147e-01, -8.8677e-02, -2.7281e-01,  ...,  2.0836e-01,\n",
       "           1.6834e-01,  1.1367e-01],\n",
       "         [ 2.4184e-01,  1.4549e-01, -3.0515e-01,  ...,  6.9434e-02,\n",
       "           1.2288e-01,  4.8823e-02],\n",
       "         [ 8.6865e-02,  2.0816e-01, -4.0764e-01,  ..., -2.2029e-01,\n",
       "           1.5179e-01, -2.6461e-01],\n",
       "         [ 2.1214e-01,  6.5962e-02, -3.0006e-01,  ..., -1.3569e-02,\n",
       "           1.0392e-01,  2.1694e-01],\n",
       "         [ 1.2214e-01,  5.3069e-02, -4.7528e-01,  ..., -4.3133e-02,\n",
       "           1.7594e-01, -1.4247e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[ 8.0372e-02,  1.9935e-01, -2.9756e-01,  ..., -6.6595e-03,\n",
       "           2.5109e-01, -3.6720e-02],\n",
       "         [ 1.0870e-01,  1.0709e-01, -2.5714e-01,  ..., -4.1395e-02,\n",
       "           1.7428e-01, -1.4675e-01],\n",
       "         [ 1.1169e-01,  1.8193e-01, -3.0169e-01,  ..., -4.5975e-03,\n",
       "           2.1134e-01, -1.0953e-01],\n",
       "         [ 1.4113e-01,  2.2608e-01, -4.7142e-01,  ..., -1.2317e-01,\n",
       "           1.2871e-01, -1.5154e-01],\n",
       "         [ 8.6835e-02,  9.1421e-02, -4.6825e-01,  ..., -1.1701e-01,\n",
       "           2.1530e-01, -1.0391e-01],\n",
       "         [ 1.2713e-01,  2.4539e-01, -3.5155e-01,  ..., -1.9771e-02,\n",
       "           2.8545e-01, -1.3454e-01]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attn_base = SDPAMHA(d_model=d_model, num_heads=4, p_drop=0.1, use_rope=False, rel_bias=None)\n",
    "test_attn_base(X_ids, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0c209bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1203,  0.0819,  1.0217,  ...,  0.1773, -0.1169, -0.2097],\n",
       "         [-0.0564,  0.1021,  0.5484,  ..., -0.0596, -0.3017, -0.0144],\n",
       "         [ 0.0375,  0.2190,  0.9778,  ...,  0.2113, -0.3425, -0.1834],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.5148,  0.3040,  0.2782,  ..., -0.2069, -0.0372, -0.0615],\n",
       "         [ 0.3745,  0.2437,  0.2511,  ..., -0.0970, -0.0199, -0.0289],\n",
       "         [ 0.2498,  0.2925,  0.1969,  ..., -0.1357,  0.0079, -0.0318],\n",
       "         [ 0.2801,  0.1823,  0.1290,  ..., -0.1760, -0.0445, -0.0606],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.1756,  0.0578, -0.0193,  ..., -0.2550, -0.0818, -0.1166],\n",
       "         [-0.3312,  0.1054, -0.0264,  ..., -0.0339, -0.2005, -0.0836],\n",
       "         [-0.2390,  0.0074, -0.0740,  ..., -0.1291, -0.1924, -0.2211],\n",
       "         [-0.1926,  0.1008,  0.0249,  ..., -0.1190, -0.1413, -0.2189],\n",
       "         [-0.3113, -0.0038, -0.0820,  ..., -0.2494, -0.0549, -0.2065],\n",
       "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0332, -0.0128,  0.4619,  ..., -0.2082, -0.1955, -0.3159],\n",
       "         [ 0.1890, -0.0270,  0.3395,  ..., -0.3052, -0.1553, -0.1826],\n",
       "         [ 0.0795,  0.0340,  0.3364,  ..., -0.0877, -0.1578, -0.3110],\n",
       "         [ 0.0910, -0.0740,  0.4113,  ..., -0.3190, -0.1471, -0.2332],\n",
       "         [ 0.1114,  0.0921,  0.3309,  ..., -0.2130, -0.1045, -0.1745],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.2135,  0.1703,  0.5347,  ..., -0.1528, -0.1032, -0.1788],\n",
       "         [-0.1521,  0.2059,  0.4194,  ..., -0.1162, -0.0871, -0.2146],\n",
       "         [-0.2066,  0.1358,  0.5074,  ..., -0.0595, -0.2003, -0.1576],\n",
       "         [ 0.0479,  0.3368,  0.5233,  ...,  0.0025,  0.0451, -0.0972],\n",
       "         [-0.2533,  0.0618,  0.3100,  ..., -0.3710, -0.0772, -0.2685],\n",
       "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
       "\n",
       "        [[ 0.0413, -0.1175,  0.2678,  ...,  0.1747, -0.0645, -0.1080],\n",
       "         [ 0.0086, -0.1973,  0.4425,  ...,  0.1107,  0.0155, -0.0301],\n",
       "         [ 0.0123, -0.1000,  0.3868,  ...,  0.2394,  0.0243, -0.0952],\n",
       "         [ 0.2230, -0.0559,  0.2205,  ...,  0.2948, -0.0460, -0.0696],\n",
       "         [-0.0090, -0.0688,  0.3628,  ...,  0.1461,  0.0900, -0.0993],\n",
       "         [ 0.0589, -0.1120,  0.4083,  ...,  0.1821,  0.0942, -0.0846]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attn = SDPAMHA(d_model=d_model, num_heads=4, p_drop=0.1, use_rope=False, rel_bias=ClippedRelPosBias(4))\n",
    "test_attn(X_ids, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce17a4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2913, -1.9837,  1.1537,  ...,  1.2065, -0.3974,  0.8566],\n",
       "         [ 0.3824,  0.6312, -0.0348,  ..., -0.1078, -0.3644,  0.2711],\n",
       "         [-1.5770, -1.0095, -0.5870,  ...,  1.1273, -1.5503,  2.0250],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ..., -0.0632, -0.0425, -0.0380],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ..., -0.0632, -0.0425, -0.0380],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ..., -0.0632, -0.0425, -0.0380]],\n",
       "\n",
       "        [[-0.8735,  0.3605,  0.3083,  ...,  0.2514,  0.2068,  0.6130],\n",
       "         [-1.1872,  1.3559,  1.2867,  ..., -0.3615,  2.5537, -1.8473],\n",
       "         [-0.7304,  1.0131, -0.1052,  ...,  0.3780, -1.8876, -1.8145],\n",
       "         [ 1.6754,  1.1961, -1.1641,  ...,  1.8507, -0.8605,  0.8219],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ..., -0.0632, -0.0425,  0.0000],\n",
       "         [ 0.0000, -0.0563,  0.0144,  ..., -0.0632,  0.0000, -0.0380]],\n",
       "\n",
       "        [[ 1.5728,  0.4876,  1.1922,  ...,  0.7780, -2.5383, -1.3821],\n",
       "         [ 0.7214, -2.4537, -0.3922,  ...,  0.1538, -1.9146, -0.6202],\n",
       "         [ 0.7222,  0.3917,  0.2760,  ...,  1.2380, -1.2837,  0.0454],\n",
       "         [-1.8838,  0.8049, -0.6835,  ..., -0.1244, -3.1849,  0.3751],\n",
       "         [ 1.5324,  0.0456,  0.5957,  ...,  0.9308, -0.0632, -1.5784],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ..., -0.0632, -0.0425, -0.0380]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9624,  0.6593,  1.5338,  ...,  0.4116, -1.1443, -1.8437],\n",
       "         [ 0.5893, -0.1834,  1.3388,  ..., -0.8286, -1.3993, -0.4479],\n",
       "         [ 0.1008, -0.1112,  1.5987,  ...,  0.4929,  0.4263, -1.8992],\n",
       "         [-0.7354, -0.1387,  0.1005,  ..., -0.0808,  0.4621,  0.5683],\n",
       "         [ 0.3350, -1.5478,  1.2966,  ..., -0.0412,  0.8601,  0.6992],\n",
       "         [ 0.0544, -0.0563,  0.0000,  ...,  0.0000, -0.0425, -0.0380]],\n",
       "\n",
       "        [[ 0.2597, -1.2154,  1.5224,  ...,  0.4790, -0.7012, -0.1699],\n",
       "         [-1.1063, -0.4202, -0.2201,  ...,  0.8226, -0.5268, -0.3776],\n",
       "         [-0.0304, -1.5725, -0.3144,  ..., -0.0827, -0.8730,  1.3277],\n",
       "         [ 0.5471,  0.3396,  0.5075,  ..., -0.4193, -0.5710, -0.7213],\n",
       "         [-0.0531, -0.9422, -1.6538,  ..., -0.7734, -1.0607, -1.4632],\n",
       "         [ 0.0544, -0.0563,  0.0144,  ...,  0.0000, -0.0425,  0.0000]],\n",
       "\n",
       "        [[-0.9683,  0.4348, -0.9529,  ..., -0.6415,  1.1970,  0.6510],\n",
       "         [-1.1211, -0.7089,  0.0648,  ..., -0.9545, -0.3183,  0.9402],\n",
       "         [-0.2255,  0.7507,  2.2450,  ...,  0.4960, -0.8196, -0.9668],\n",
       "         [-0.9032,  0.1794, -0.7398,  ..., -0.5814, -1.7426,  1.8561],\n",
       "         [-1.0721,  0.6477, -0.5477,  ...,  0.8141, -1.3875,  0.8085],\n",
       "         [ 1.1165, -0.2311,  0.1809,  ...,  0.8041,  0.0987, -0.7115]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_block = make_block(d_model)\n",
    "dummy_block(X_ids, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a779c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7546c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, epoch 5, ['loss: 1.072036623954773', 'acc: 0.75', 'brier: 0.2785666584968567', 'margin: 0.3352586030960083']\n",
      "Fold 2, epoch 5, ['loss: 1.3459709882736206', 'acc: 0.3333333432674408', 'brier: 0.49663570523262024', 'margin: 0.31585898995399475']\n",
      "Fold 3, epoch 5, ['loss: 0.95474773645401', 'acc: 0.6666666865348816', 'brier: 0.2979356050491333', 'margin: 0.3949678838253021']\n",
      "Fold 4, epoch 5, ['loss: 1.465563178062439', 'acc: 0.6666666865348816', 'brier: 0.36048707365989685', 'margin: 0.3280555307865143']\n",
      "Fold 5, epoch 5, ['loss: 0.576449453830719', 'acc: 0.6666666865348816', 'brier: 0.20134033262729645', 'margin: 0.23472516238689423']\n"
     ]
    }
   ],
   "source": [
    "# 3) Train with k-fold\n",
    "cfg = TrainConfig(epochs=40, batch_size=None, lr_enc=3e-3, warmup_steps=0)\n",
    "result = kfold_train(X, y_float, y_long, M, lambda: make_model(vocab_size, d_model, pad_id, cls_id), cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6407ef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'folds': [{'loss': 0.7314648628234863,\n",
       "   'acc': 0.5,\n",
       "   'brier': 0.26776188611984253,\n",
       "   'margin': 0.08592170476913452},\n",
       "  {'loss': 0.8871936798095703,\n",
       "   'acc': 0.3333333432674408,\n",
       "   'brier': 0.3426041901111603,\n",
       "   'margin': 0.12830226123332977},\n",
       "  {'loss': 0.8276603817939758,\n",
       "   'acc': 0.6666666865348816,\n",
       "   'brier': 0.2919054329395294,\n",
       "   'margin': 0.24631471931934357},\n",
       "  {'loss': 0.6768187880516052,\n",
       "   'acc': 0.6666666865348816,\n",
       "   'brier': 0.2418615072965622,\n",
       "   'margin': 0.04568130895495415},\n",
       "  {'loss': 0.550352156162262,\n",
       "   'acc': 0.6666666865348816,\n",
       "   'brier': 0.18369753658771515,\n",
       "   'margin': 0.15188170969486237}],\n",
       " 'mean': {'loss': 0.7346979737281799,\n",
       "  'acc': 0.5666666805744172,\n",
       "  'brier': 0.2655661106109619,\n",
       "  'margin': 0.13162034079432489},\n",
       " 'std': {'loss': 0.11767819108178501,\n",
       "  'acc': 0.13333333879709255,\n",
       "  'brier': 0.052721567986518274,\n",
       "  'margin': 0.0678972984955782}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representation_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
